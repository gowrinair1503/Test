# -*- coding: utf-8 -*-
"""Untitled60.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cm7yQArTIoegMmDGQ_5ux0vlU3gt-iUO
"""

import cv2
import numpy as np
from google.colab.patches import cv2_imshow

from google.colab import drive
drive.mount('/content/drive')

import zipfile
zip_path = "/content/drive/MyDrive/Test Kit  2.v1i.yolov8.zip"
extract_path = "/content/test_kit_dataset"

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

!sudo apt install tesseract-ocr
!pip install pytesseract

!pip install ultralytics
from ultralytics import YOLO

model = YOLO('yolov8n.pt')
model.train(data="/content/test_kit_dataset/data (5).yaml", epochs=50, imgsz=640)

# Load model
from ultralytics import YOLO
import cv2

model = YOLO('/content/runs/detect/train/weights/best.pt')
results = model('/content/20250208_151217.jpg', conf=0.25)

# result saved in list form
res = results[0]

img = cv2.imread('/content/20250208_151217.jpg')
img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

for box in res.boxes:
    cls_id = int(box.cls[0])
    label = res.names[cls_id]
    conf = float(box.conf[0])

    x1, y1, x2, y2 = map(int, box.xyxy[0])

    # Draw bounding box
    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
    text = f"{label} {conf:.2f}"
    cv2.putText(img, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX,
                0.6, (0, 255, 0), 2)

    if label == "D":
        x1, y1, x2, y2 = map(int, box.xyxy[0])
        test_crop = img[y1:y2, x1:x2]
        cv2.imwrite("test_crop.jpg", test_crop)
        print(f"Cropped test region saved!")
    else:
        test_type=label
        print("Detected:", label)

import matplotlib.pyplot as plt
img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
plt.figure(figsize=(10, 8))
plt.imshow(img_rgb)
plt.axis('off')
plt.title("Detections")
plt.show()

if test_crop is not None:
    plt.subplot(1, 2, 2)
    plt.imshow(test_crop)
    plt.axis('off')
plt.tight_layout()
plt.show()

test_crop = cv2.imread("test_crop.jpg")
test_crop_rgb = cv2.cvtColor(test_crop, cv2.COLOR_BGR2RGB)
r_channel = test_crop_rgb[:, :, 2]


clahe = cv2.createCLAHE(clipLimit=1.0, tileGridSize=(8, 8))
r_channel_clahe = clahe.apply(r_channel)
plt.figure(figsize=(10, 4))
plt.subplot(1, 2, 2)
plt.imshow(r_channel_clahe, cmap='gray')
plt.axis('off')

plt.tight_layout()
plt.show()

import cv2
import numpy as np

def analyze_test_result(test_img_path, test_type):
    img = cv2.imread(test_img_path)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # Blur to reduce noise
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)
    _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    contours = sorted(contours, key=lambda c: cv2.boundingRect(c)[1])

    if len(contours) < 2:
        return "Negative (only one line detected)"

    line1 = contours[0]
    line2 = contours[1]

    x1, y1, w1, h1 = cv2.boundingRect(line1)
    x2, y2, w2, h2 = cv2.boundingRect(line2)


    line1_roi = gray[y1:y1+h1, x1:x1+w1] #Average intensities
    line2_roi = gray[y2:y2+h2, x2:x2+w2]

    intensity1 = np.mean(line1_roi)
    intensity2 = np.mean(line2_roi)

    print("Intensity 1:", intensity1)
    print("Intensity 2:", intensity2)
    if test_type.lower() == "ezeefind":
        return "Positive" if intensity2 < 240 else "Negative"
    elif test_type.lower() == "ovufind":
        return "Positive" if intensity2 >= intensity1 else "Negative"
    elif test_type.lower() == "menofind":
        return "Positive" if intensity2 > intensity1 else "Negative"
    else:
        return "Unknown test type"

result = analyze_test_result("/content/test_crop.jpg", test_type)
print("Test Type:", test_type)
print("Result:", result)